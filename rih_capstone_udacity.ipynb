{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhheadquarters/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#start with imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE ARE GOING TO BE PREDICTING WHETHER A HURRICANE WILL RANDOMLY INTENSIFY OR NOT.\n",
    "#FIRST WE WILL BRING IN THE DATASET\n",
    "#CLEAN THE DATASET\n",
    "#REMOVE NULL VALUES AND CATEGORICAL DATA\n",
    "#VISUALIZE THE REMAINING 0 VALUES WITHIN THE DATA\n",
    "#BRING IN THE RANDOMFORESTCLASSIFIER\n",
    "#TRAIN THE DATA AND SEE WHAT THE PREDICTED DVMAX IS?\n",
    "#IF THE DVMAX IS PREDICTED TO BE OVER 25 KNOTS THEN STORE AS 1 AND IF NOT THEN STORE AS 0\n",
    "#CONVERT THE DVMAX_ANSWER COLUMN INTO AN ARRAY OF 1'S FOR OVER 25 KNOTS AND 0 FOR UNDER 25 KNOTS\n",
    "#RUN THROUGH RANDOM FOREST WITHOUT ANY ADJUSTMENTS TO CLASSIFIER\n",
    "#ADJUST THE HYPERPARAMETERS AND THEN RUN IT AGAIN\n",
    "#USE FEATURE EXTRACTION TO UNDERSTAND AND BE ABLE TO TRAIN ON THE BEST COLUMNS\n",
    "#WE SHOULD ACHIEVE 25% AND 30% ACCURACY AS THAT WAS THE SCORES DURING THE LATEST COMPETITION WITH SAME DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vmax</th>\n",
       "      <th>dvmax</th>\n",
       "      <th>clat</th>\n",
       "      <th>clon</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>RHCN</th>\n",
       "      <th>NOHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>SHRD2</th>\n",
       "      <th>SHRG</th>\n",
       "      <th>DIVC</th>\n",
       "      <th>U200</th>\n",
       "      <th>EPSS</th>\n",
       "      <th>ENSS</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>PC1</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>AVBT2</th>\n",
       "      <th>SDBT2</th>\n",
       "      <th>PX10</th>\n",
       "      <th>PX20</th>\n",
       "      <th>PX50</th>\n",
       "      <th>TBMX</th>\n",
       "      <th>RSST</th>\n",
       "      <th>BTAV</th>\n",
       "      <th>SHTD</th>\n",
       "      <th>SHGC</th>\n",
       "      <th>T200</th>\n",
       "      <th>T250</th>\n",
       "      <th>Z850</th>\n",
       "      <th>EPOS</th>\n",
       "      <th>RHMD</th>\n",
       "      <th>TADV</th>\n",
       "      <th>DTL</th>\n",
       "      <th>PSLV</th>\n",
       "      <th>UMOV</th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-27 12:00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.562555</td>\n",
       "      <td>6.3</td>\n",
       "      <td>103.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.8</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-473.0</td>\n",
       "      <td>-364.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-54.3</td>\n",
       "      <td>27.4</td>\n",
       "      <td>-57.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-537.0</td>\n",
       "      <td>-411.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.161867</td>\n",
       "      <td>505.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>7.05708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  vmax  dvmax  clat  clon    MSLP       PER  SHRD  \\\n",
       "0  1998-07-27 12:00:00  25.0    5.0  11.3 -25.4  1009.0  3.562555   6.3   \n",
       "\n",
       "    D200  RHLO  PX30   SDBT    POT  RHCN  NOHC  TPW   PC2  SHRD2  SHRG   DIVC  \\\n",
       "0  103.0  68.0  72.0  138.0 -101.0   0.0  12.0  0.0 -58.0    1.7  24.8  129.0   \n",
       "\n",
       "   U200  EPSS  ENSS  TPWC  PC1   AVBT  AVBT2  SDBT2  PX10  PX20  PX50  TBMX  \\\n",
       "0  -7.9   2.1   3.0  55.7  0.0 -473.0 -364.0  187.0  98.0  82.0  42.0 -54.3   \n",
       "\n",
       "   RSST  BTAV  SHTD   SHGC   T200   T250  Z850  EPOS  RHMD  TADV         DTL  \\\n",
       "0  27.4 -57.3   0.1  203.0 -537.0 -411.0  72.0   7.1  67.0   0.0  270.161867   \n",
       "\n",
       "    PSLV  UMOV       VS  \n",
       "0  505.0 -96.0  7.05708  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ships_TRAIN.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vmax</th>\n",
       "      <th>dvmax</th>\n",
       "      <th>clat</th>\n",
       "      <th>clon</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>RHCN</th>\n",
       "      <th>NOHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>SHRD2</th>\n",
       "      <th>SHRG</th>\n",
       "      <th>DIVC</th>\n",
       "      <th>U200</th>\n",
       "      <th>EPSS</th>\n",
       "      <th>ENSS</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>PC1</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>AVBT2</th>\n",
       "      <th>SDBT2</th>\n",
       "      <th>PX10</th>\n",
       "      <th>PX20</th>\n",
       "      <th>PX50</th>\n",
       "      <th>TBMX</th>\n",
       "      <th>RSST</th>\n",
       "      <th>BTAV</th>\n",
       "      <th>SHTD</th>\n",
       "      <th>SHGC</th>\n",
       "      <th>T200</th>\n",
       "      <th>T250</th>\n",
       "      <th>Z850</th>\n",
       "      <th>EPOS</th>\n",
       "      <th>RHMD</th>\n",
       "      <th>TADV</th>\n",
       "      <th>DTL</th>\n",
       "      <th>PSLV</th>\n",
       "      <th>UMOV</th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-07-27 12:00:00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-25.4</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>3.562555</td>\n",
       "      <td>6.3</td>\n",
       "      <td>103.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.8</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-473.0</td>\n",
       "      <td>-364.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-54.3</td>\n",
       "      <td>27.4</td>\n",
       "      <td>-57.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-537.0</td>\n",
       "      <td>-411.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.161867</td>\n",
       "      <td>505.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>7.05708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  vmax  dvmax  clat  clon    MSLP       PER  SHRD  \\\n",
       "0  1998-07-27 12:00:00  25.0    5.0  11.3 -25.4  1009.0  3.562555   6.3   \n",
       "\n",
       "    D200  RHLO  PX30   SDBT    POT  RHCN  NOHC  TPW   PC2  SHRD2  SHRG   DIVC  \\\n",
       "0  103.0  68.0  72.0  138.0 -101.0   0.0  12.0  0.0 -58.0    1.7  24.8  129.0   \n",
       "\n",
       "   U200  EPSS  ENSS  TPWC  PC1   AVBT  AVBT2  SDBT2  PX10  PX20  PX50  TBMX  \\\n",
       "0  -7.9   2.1   3.0  55.7  0.0 -473.0 -364.0  187.0  98.0  82.0  42.0 -54.3   \n",
       "\n",
       "   RSST  BTAV  SHTD   SHGC   T200   T250  Z850  EPOS  RHMD  TADV         DTL  \\\n",
       "0  27.4 -57.3   0.1  203.0 -537.0 -411.0  72.0   7.1  67.0   0.0  270.161867   \n",
       "\n",
       "    PSLV  UMOV       VS  \n",
       "0  505.0 -96.0  7.05708  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we need to rename the first column to be date\n",
    "df.rename(columns={'Unnamed: 0' : 'date'}, inplace = True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vmax</th>\n",
       "      <th>dvmax</th>\n",
       "      <th>clat</th>\n",
       "      <th>clon</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>RHCN</th>\n",
       "      <th>NOHC</th>\n",
       "      <th>TPW</th>\n",
       "      <th>PC2</th>\n",
       "      <th>SHRD2</th>\n",
       "      <th>SHRG</th>\n",
       "      <th>DIVC</th>\n",
       "      <th>U200</th>\n",
       "      <th>EPSS</th>\n",
       "      <th>ENSS</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>PC1</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>AVBT2</th>\n",
       "      <th>SDBT2</th>\n",
       "      <th>PX10</th>\n",
       "      <th>PX20</th>\n",
       "      <th>PX50</th>\n",
       "      <th>TBMX</th>\n",
       "      <th>RSST</th>\n",
       "      <th>BTAV</th>\n",
       "      <th>SHTD</th>\n",
       "      <th>SHGC</th>\n",
       "      <th>T200</th>\n",
       "      <th>T250</th>\n",
       "      <th>Z850</th>\n",
       "      <th>EPOS</th>\n",
       "      <th>RHMD</th>\n",
       "      <th>TADV</th>\n",
       "      <th>DTL</th>\n",
       "      <th>PSLV</th>\n",
       "      <th>UMOV</th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.0</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "      <td>5591.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.132673</td>\n",
       "      <td>1.610309</td>\n",
       "      <td>24.316416</td>\n",
       "      <td>-64.513921</td>\n",
       "      <td>990.399604</td>\n",
       "      <td>2.470309</td>\n",
       "      <td>15.680079</td>\n",
       "      <td>34.240792</td>\n",
       "      <td>69.867129</td>\n",
       "      <td>56.136247</td>\n",
       "      <td>161.443167</td>\n",
       "      <td>-67.464752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.309495</td>\n",
       "      <td>152.654375</td>\n",
       "      <td>5.501613</td>\n",
       "      <td>17.430752</td>\n",
       "      <td>24.493960</td>\n",
       "      <td>34.084879</td>\n",
       "      <td>6.862812</td>\n",
       "      <td>3.728931</td>\n",
       "      <td>3.472792</td>\n",
       "      <td>57.798000</td>\n",
       "      <td>16.895665</td>\n",
       "      <td>-348.203436</td>\n",
       "      <td>-257.407559</td>\n",
       "      <td>213.266103</td>\n",
       "      <td>70.336703</td>\n",
       "      <td>63.270928</td>\n",
       "      <td>37.770542</td>\n",
       "      <td>-32.036994</td>\n",
       "      <td>27.645901</td>\n",
       "      <td>-37.340664</td>\n",
       "      <td>13.002653</td>\n",
       "      <td>247.271881</td>\n",
       "      <td>-532.091287</td>\n",
       "      <td>-416.124158</td>\n",
       "      <td>28.096832</td>\n",
       "      <td>9.105941</td>\n",
       "      <td>56.914059</td>\n",
       "      <td>2.574059</td>\n",
       "      <td>270.018038</td>\n",
       "      <td>614.714495</td>\n",
       "      <td>-17.188429</td>\n",
       "      <td>4.186561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.058662</td>\n",
       "      <td>16.949435</td>\n",
       "      <td>7.867046</td>\n",
       "      <td>18.568310</td>\n",
       "      <td>19.556055</td>\n",
       "      <td>8.677754</td>\n",
       "      <td>9.544277</td>\n",
       "      <td>37.276699</td>\n",
       "      <td>6.847872</td>\n",
       "      <td>26.560179</td>\n",
       "      <td>62.290871</td>\n",
       "      <td>38.199781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.921247</td>\n",
       "      <td>218.854321</td>\n",
       "      <td>89.632366</td>\n",
       "      <td>9.544723</td>\n",
       "      <td>10.492456</td>\n",
       "      <td>38.751077</td>\n",
       "      <td>14.372824</td>\n",
       "      <td>2.300312</td>\n",
       "      <td>2.361707</td>\n",
       "      <td>7.278464</td>\n",
       "      <td>9.118924</td>\n",
       "      <td>200.626189</td>\n",
       "      <td>161.426420</td>\n",
       "      <td>63.079385</td>\n",
       "      <td>24.874438</td>\n",
       "      <td>26.082741</td>\n",
       "      <td>25.358179</td>\n",
       "      <td>28.665204</td>\n",
       "      <td>2.102631</td>\n",
       "      <td>27.467916</td>\n",
       "      <td>8.872060</td>\n",
       "      <td>104.801477</td>\n",
       "      <td>16.666984</td>\n",
       "      <td>21.937018</td>\n",
       "      <td>55.433061</td>\n",
       "      <td>3.008730</td>\n",
       "      <td>10.589331</td>\n",
       "      <td>12.202751</td>\n",
       "      <td>197.840595</td>\n",
       "      <td>76.320406</td>\n",
       "      <td>44.424327</td>\n",
       "      <td>29.181274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>-105.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-143.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-225.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-34.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-807.000000</td>\n",
       "      <td>-716.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-85.400000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>-86.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-619.000000</td>\n",
       "      <td>-521.000000</td>\n",
       "      <td>-170.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-112.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>-126.000000</td>\n",
       "      <td>-145.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>-79.100000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>118.102023</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>54.700000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-504.000000</td>\n",
       "      <td>-364.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-57.300000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>-61.200000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>-540.000000</td>\n",
       "      <td>-423.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>229.834543</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>-46.000000</td>\n",
       "      <td>-5.017028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.815745</td>\n",
       "      <td>24.316416</td>\n",
       "      <td>-64.513921</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>2.444917</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>34.240792</td>\n",
       "      <td>69.867129</td>\n",
       "      <td>56.136151</td>\n",
       "      <td>161.338785</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>5.485497</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.118492</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>3.728931</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>58.100000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-348.146559</td>\n",
       "      <td>-257.440739</td>\n",
       "      <td>213.177358</td>\n",
       "      <td>70.260620</td>\n",
       "      <td>63.232158</td>\n",
       "      <td>37.866185</td>\n",
       "      <td>-32.008836</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-37.313658</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>-532.091287</td>\n",
       "      <td>-415.000000</td>\n",
       "      <td>28.096832</td>\n",
       "      <td>9.105941</td>\n",
       "      <td>56.914059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>270.161867</td>\n",
       "      <td>614.703667</td>\n",
       "      <td>-17.184987</td>\n",
       "      <td>2.362440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-50.900000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>62.300000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-226.500000</td>\n",
       "      <td>-148.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-8.350000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-18.600000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>-523.000000</td>\n",
       "      <td>-404.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>270.161867</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.090380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>50.700000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1022.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>67.600000</td>\n",
       "      <td>93.700000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>78.800000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>896.000000</td>\n",
       "      <td>-457.000000</td>\n",
       "      <td>-361.000000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>346.214000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              vmax        dvmax         clat         clon         MSLP  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean     55.132673     1.610309    24.316416   -64.513921   990.399604   \n",
       "std      26.058662    16.949435     7.867046    18.568310    19.556055   \n",
       "min      15.000000  -110.000000     8.900000  -105.000000   882.000000   \n",
       "25%      35.000000    -5.000000    17.750000   -79.100000   985.000000   \n",
       "50%      50.000000     1.815745    24.316416   -64.513921   995.000000   \n",
       "75%      65.000000    10.000000    30.000000   -50.900000  1005.000000   \n",
       "max     160.000000    95.000000    50.700000    -6.000000  1022.000000   \n",
       "\n",
       "               PER         SHRD         D200         RHLO         PX30  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean      2.470309    15.680079    34.240792    69.867129    56.136247   \n",
       "std       8.677754     9.544277    37.276699     6.847872    26.560179   \n",
       "min     -45.000000     0.000000   -95.000000    41.000000     0.000000   \n",
       "25%       0.000000     8.900000    10.000000    66.000000    38.000000   \n",
       "50%       2.444917    15.000000    34.240792    69.867129    56.136151   \n",
       "75%       5.000000    19.800000    55.000000    74.000000    77.000000   \n",
       "max      75.000000    74.200000   205.000000    90.000000   100.000000   \n",
       "\n",
       "              SDBT          POT    RHCN         NOHC          TPW  \\\n",
       "count  5591.000000  5591.000000  5591.0  5591.000000  5591.000000   \n",
       "mean    161.443167   -67.464752     0.0    34.309495   152.654375   \n",
       "std      62.290871    38.199781     0.0    30.921247   218.854321   \n",
       "min      19.000000  -143.000000     0.0     0.000000     0.000000   \n",
       "25%     118.102023   -97.000000     0.0     8.000000     0.000000   \n",
       "50%     161.338785   -68.000000     0.0    32.000000    46.000000   \n",
       "75%     196.000000   -44.000000     0.0    52.000000   161.000000   \n",
       "max     398.000000    85.000000     0.0   222.000000   900.000000   \n",
       "\n",
       "               PC2        SHRD2         SHRG         DIVC         U200  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean      5.501613    17.430752    24.493960    34.084879     6.862812   \n",
       "std      89.632366     9.544723    10.492456    38.751077    14.372824   \n",
       "min    -225.000000     0.200000     4.800000   -95.000000   -34.800000   \n",
       "25%     -61.000000    10.700000    17.100000    10.000000    -2.900000   \n",
       "50%       5.485497    17.400000    24.000000    34.118492     6.800000   \n",
       "75%      62.000000    22.100000    29.300000    56.000000    14.900000   \n",
       "max     252.000000    67.600000    93.700000   214.000000    69.500000   \n",
       "\n",
       "              EPSS         ENSS         TPWC          PC1         AVBT  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean      3.728931     3.472792    57.798000    16.895665  -348.203436   \n",
       "std       2.300312     2.361707     7.278464     9.118924   200.626189   \n",
       "min       0.000000     1.000000    27.600000     0.000000  -807.000000   \n",
       "25%       2.100000     2.200000    54.700000    15.000000  -504.000000   \n",
       "50%       3.728931     2.700000    58.100000    15.000000  -348.146559   \n",
       "75%       5.300000     3.500000    62.300000    15.000000  -226.500000   \n",
       "max      11.900000    22.800000    78.800000    45.000000   188.000000   \n",
       "\n",
       "             AVBT2        SDBT2         PX10         PX20         PX50  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean   -257.407559   213.266103    70.336703    63.270928    37.770542   \n",
       "std     161.426420    63.079385    24.874438    26.082741    25.358179   \n",
       "min    -716.000000    30.000000     0.000000     0.000000     0.000000   \n",
       "25%    -364.000000   173.000000    55.000000    46.000000    18.000000   \n",
       "50%    -257.440739   213.177358    70.260620    63.232158    37.866185   \n",
       "75%    -148.000000   251.000000    93.000000    86.000000    52.000000   \n",
       "max     190.000000   417.000000   100.000000   100.000000   100.000000   \n",
       "\n",
       "              TBMX         RSST         BTAV         SHTD         SHGC  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean    -32.036994    27.645901   -37.340664    13.002653   247.271881   \n",
       "std      28.665204     2.102631    27.467916     8.872060   104.801477   \n",
       "min     -85.400000    11.900000   -86.200000     0.000000    50.000000   \n",
       "25%     -57.300000    27.300000   -61.200000     6.200000   173.000000   \n",
       "50%     -32.008836    28.000000   -37.313658    11.500000   239.000000   \n",
       "75%      -8.350000    29.000000   -18.600000    17.300000   292.000000   \n",
       "max      22.900000    31.500000    21.200000    35.900000   896.000000   \n",
       "\n",
       "              T200         T250         Z850         EPOS         RHMD  \\\n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000   \n",
       "mean   -532.091287  -416.124158    28.096832     9.105941    56.914059   \n",
       "std      16.666984    21.937018    55.433061     3.008730    10.589331   \n",
       "min    -619.000000  -521.000000  -170.000000     0.000000    19.000000   \n",
       "25%    -540.000000  -423.000000    -4.000000     7.400000    50.000000   \n",
       "50%    -532.091287  -415.000000    28.096832     9.105941    56.914059   \n",
       "75%    -523.000000  -404.000000    59.000000    11.100000    64.000000   \n",
       "max    -457.000000  -361.000000   278.000000    18.000000    86.000000   \n",
       "\n",
       "              TADV          DTL         PSLV         UMOV           VS  \n",
       "count  5591.000000  5591.000000  5591.000000  5591.000000  5591.000000  \n",
       "mean      2.574059   270.018038   614.714495   -17.188429     4.186561  \n",
       "std      12.202751   197.840595    76.320406    44.424327    29.181274  \n",
       "min    -112.000000  -822.000000   301.000000  -126.000000  -145.343000  \n",
       "25%      -1.000000   229.834543   567.000000   -46.000000    -5.017028  \n",
       "50%       1.000000   270.161867   614.703667   -17.184987     2.362440  \n",
       "75%       5.000000   270.161867   660.000000     5.000000     9.090380  \n",
       "max     360.000000   900.000000   899.000000   239.000000   346.214000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to show all the column and visibly look for 0 values in the min category of describe\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns with a minimum of 0 or potential 0 values that need to be accounted for\n",
    "- per \n",
    "- shrd\n",
    "- px30\n",
    "- rhcn - this one looks bad\n",
    "- nohc\n",
    "- tpw\n",
    "- epss\n",
    "- pc1\n",
    "- px10\n",
    "- px20\n",
    "- px50\n",
    "- shtd\n",
    "- epos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run a for loop over the columns with 0 values. find out which columns have the most 0's\n",
    "#lets visualize ssome zeros    \n",
    "zero_columns = ['PER', 'SHRD', 'PX30', 'RHCN', 'NOHC',\n",
    "                'TPW', 'EPSS', 'PC1', 'PX10', 'PX20',\n",
    "                'PX50', 'SHTD', 'EPOS', 'TADV']\n",
    "\n",
    "def zero_test(df):\n",
    "    '''Find the amount of zeros per column. \n",
    "    This is done after NaN values have been calculated\n",
    "    return a barchart showing the percent of zeros in descending order\n",
    "    '''\n",
    "    zero_dict = {}\n",
    "    for column in zero_columns:\n",
    "        zeros = df[df[column] == 0]\n",
    "        \n",
    "        total = zeros.shape[0]\n",
    "        percent_total = zeros.shape[0] / df.shape[0]\n",
    "        column_total = str(column) + ': ' + str(total)\n",
    "        \n",
    "        zero_dict.update( {column_total : percent_total})\n",
    "        \n",
    "    zero_dict = OrderedDict(sorted(zero_dict.items(), \n",
    "                                  key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    plt.bar(range(len(zero_dict)), list(zero_dict.values()), align='center')\n",
    "    plt.xticks(range(len(zero_dict)), list(zero_dict.keys()))\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    plt.title('Percent of 0 values in columns with zeros', fontsize = 20)\n",
    "    plt.ylabel(\"percent of 0's\", fontsize=16)\n",
    "    plt.xlabel('column name and total amount of zeros', fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return zero_dict\n",
    "        \n",
    "zero_dict = zero_test(df)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at what these columns are in order to make a judgement on what the correct thing to do with each column is.\n",
    "\n",
    "- The RHCN is ocean heat content from satellite altimeter data\n",
    "- The TPW is total precipitable water\n",
    "- The PER is previous 12 hour intensity change \n",
    "- The NOHC is hard to find the actual meaning of the column.\n",
    "- THE TADV is also not currently something i have found\n",
    "- The EPSS is Equivalent potential temp excess of a parcel lifted from the surface and the saturated equivalent potential temp\n",
    "- The PC1 is First principal component of GOES-IR imagery within a 440 km radius\n",
    "- The PX50 is percentage of area covered by -50 degree celsius GOES-IR brighness temp within a 50-200-km-radius\n",
    "- The PX30 percentage of area with -30degree celsius GOES-IR brightness temp (t = 0h) within a 50-200-km radius\n",
    "- The PX20 is percentage of area covered by -20 degree celsius GOES-IR brightness temp (t = 0h) within a 50200-km radius \n",
    "- The PX10 is Percentage of area covered by -10 degree Celsius GOES-IR brightness temp (t = 0h) within a 50200-km radius  \n",
    "- The EPOS is the Average thata difference between a parcel lifted from the surface and its environment averaged from 200-800 km. \n",
    "- The SHTD is not understood yet\n",
    "- The SHRD 850-200-hPa vertical shear within a 500-km radius after vortex \n",
    "\n",
    "OK. We are going to drop both the RHCN and TPW columns entirely.\n",
    "The PER column is understandibly going to have 0 values as sometimes there wont be a 12 hour change in intensity.\n",
    "\n",
    "The NOHC and TADV columns have been impossible to find out what it is thus far. I have decided to delete the columns entirely as we still have a significant dataframe of features.\n",
    "\n",
    "The rest of the rows with 0 values will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting rid of 0 values\n",
    "#WE DROPPING NOHC AND TADV WHICH WASNT ORIGINALLY HAPPENING\n",
    "\n",
    "df = df.drop(['RHCN', 'TPW', 'NOHC', 'TADV'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lets get an understanding of how many rows have 0 values. There will be some overlap where rows have more then one 0.\n",
      "1219\n"
     ]
    }
   ],
   "source": [
    "#aggregate the rows of 0 value rows\n",
    "epss = df[df['EPSS'] == 0]\n",
    "pc1 = df[df['PC1'] == 0]\n",
    "px50 = df[df['PX50'] == 0]\n",
    "px30 = df[df['PX30'] == 0]\n",
    "px20 = df[df['PX20'] == 0]\n",
    "epos = df[df['EPOS'] == 0]\n",
    "px10 = df[df['PX10'] == 0]\n",
    "shtd = df[df['SHTD'] == 0]\n",
    "shrd = df[df['SHRD'] == 0]\n",
    "print('lets get an understanding of how many rows have 0 values. There will be some overlap where rows have more then one 0.')\n",
    "print(epss.shape[0] + pc1.shape[0] + px50.shape[0] + px30.shape[0] + px20.shape[0] + epos.shape[0] + px10.shape[0] + shtd.shape[0] + shrd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4626, 42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets clean this df\n",
    "df_clean = pd.concat([df, epss, pc1, px50, px30, px20, epos, px10, shtd, shrd]).drop_duplicates(keep = False)\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.           0.           5.         ...   5.         -12.4448032\n",
      "   1.81574458]\n",
      "the length of \"dvmax\" or \"y\" column is 4626\n",
      "the length of the dataframe should be the same as above 4626\n"
     ]
    }
   ],
   "source": [
    "#CONVERT DVMAX OVER INTO AN ARRAY\n",
    "#this is become our y or answers to compare the predictions to\n",
    "#https://stackoverflow.com/questions/31789160/convert-select-columns-in-pandas-dataframe-to-numpy-array\n",
    "\n",
    "dvmax_answers = df_clean.iloc[:, 2].values\n",
    "\n",
    "#check the answers \n",
    "print(dvmax_answers)\n",
    "print('the length of \"dvmax\" or \"y\" column is ' + str(len(dvmax_answers)))\n",
    "print('the length of the dataframe should be the same as above ' + str(df_clean.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>vmax</th>\n",
       "      <th>clat</th>\n",
       "      <th>clon</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>PER</th>\n",
       "      <th>SHRD</th>\n",
       "      <th>D200</th>\n",
       "      <th>RHLO</th>\n",
       "      <th>PX30</th>\n",
       "      <th>SDBT</th>\n",
       "      <th>POT</th>\n",
       "      <th>PC2</th>\n",
       "      <th>SHRD2</th>\n",
       "      <th>SHRG</th>\n",
       "      <th>DIVC</th>\n",
       "      <th>U200</th>\n",
       "      <th>EPSS</th>\n",
       "      <th>ENSS</th>\n",
       "      <th>TPWC</th>\n",
       "      <th>PC1</th>\n",
       "      <th>AVBT</th>\n",
       "      <th>AVBT2</th>\n",
       "      <th>SDBT2</th>\n",
       "      <th>PX10</th>\n",
       "      <th>PX20</th>\n",
       "      <th>PX50</th>\n",
       "      <th>TBMX</th>\n",
       "      <th>RSST</th>\n",
       "      <th>BTAV</th>\n",
       "      <th>SHTD</th>\n",
       "      <th>SHGC</th>\n",
       "      <th>T200</th>\n",
       "      <th>T250</th>\n",
       "      <th>Z850</th>\n",
       "      <th>EPOS</th>\n",
       "      <th>RHMD</th>\n",
       "      <th>DTL</th>\n",
       "      <th>PSLV</th>\n",
       "      <th>UMOV</th>\n",
       "      <th>VS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998-07-28 18:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-35.1</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>56.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-270.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>27.1</td>\n",
       "      <td>-40.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-533.0</td>\n",
       "      <td>-410.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>270.161867</td>\n",
       "      <td>579.0</td>\n",
       "      <td>-95.0</td>\n",
       "      <td>1.20054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  vmax  clat  clon    MSLP  PER  SHRD  D200  RHLO  PX30  \\\n",
       "5  1998-07-28 18:00:00  30.0  13.1 -35.1  1006.0  5.0   9.7  44.0  72.0  35.0   \n",
       "\n",
       "    SDBT   POT   PC2  SHRD2  SHRG  DIVC  U200  EPSS  ENSS  TPWC   PC1   AVBT  \\\n",
       "5  159.0 -86.0  36.0    5.3  20.0  38.0  -7.2   2.8   2.9  56.6  15.0 -270.0   \n",
       "\n",
       "   AVBT2  SDBT2  PX10  PX20  PX50  TBMX  RSST  BTAV  SHTD   SHGC   T200  \\\n",
       "5 -147.0  175.0  62.0  48.0  10.0 -33.6  27.1 -40.4   4.5  232.0 -533.0   \n",
       "\n",
       "    T250  Z850  EPOS  RHMD         DTL   PSLV  UMOV       VS  \n",
       "5 -410.0  80.0   7.5  68.0  270.161867  579.0 -95.0  1.20054  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROP DVMAX FROM THE DATAFRAME AS IT IS THE ANSWER COLUMN\n",
    "\n",
    "df_clean = df_clean.drop('dvmax', 1)\n",
    "df_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert over into X to train on and y as the answers\n",
    "X = df_clean.drop('date', 1)\n",
    "y = dvmax_answers.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#implementing train_test_split from the sklearn imports\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest model creation\n",
    "#we will be running this first with no adjusted hyperparameters in order to see how it performs all by itself.\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "rfc_predict = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527\n",
      "1527\n"
     ]
    }
   ],
   "source": [
    "#double check that both predictions and y_test are correct size\n",
    "#it just makes me feel better when I see it :)\n",
    "print(len(rfc_predict))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        -95       0.00      0.00      0.00         1\n",
      "        -90       0.00      0.00      0.00         1\n",
      "        -85       0.00      0.00      0.00         1\n",
      "        -80       0.00      0.00      0.00         1\n",
      "        -70       0.00      0.00      0.00         1\n",
      "        -65       0.20      0.17      0.18         6\n",
      "        -60       0.00      0.00      0.00         2\n",
      "        -55       0.00      0.00      0.00         3\n",
      "        -50       0.00      0.00      0.00         4\n",
      "        -45       0.00      0.00      0.00         4\n",
      "        -40       0.30      0.30      0.30        10\n",
      "        -35       0.09      0.07      0.08        14\n",
      "        -30       0.10      0.10      0.10        20\n",
      "        -25       0.07      0.06      0.06        32\n",
      "        -20       0.08      0.08      0.08        36\n",
      "        -19       0.00      0.00      0.00         1\n",
      "        -18       0.00      0.00      0.00         0\n",
      "        -17       0.00      0.00      0.00         2\n",
      "        -15       0.14      0.20      0.16        74\n",
      "        -14       0.00      0.00      0.00         2\n",
      "        -12       0.00      0.00      0.00         2\n",
      "        -11       0.00      0.00      0.00         1\n",
      "        -10       0.13      0.12      0.13       100\n",
      "         -9       0.00      0.00      0.00         0\n",
      "         -8       0.00      0.00      0.00         3\n",
      "         -7       0.00      0.00      0.00         4\n",
      "         -6       0.00      0.00      0.00         5\n",
      "         -5       0.15      0.22      0.18       133\n",
      "         -4       0.00      0.00      0.00         9\n",
      "         -3       0.00      0.00      0.00         2\n",
      "         -2       0.00      0.00      0.00         5\n",
      "         -1       0.33      0.08      0.12        13\n",
      "          0       0.16      0.22      0.19       156\n",
      "          1       0.87      0.85      0.86       224\n",
      "          2       0.00      0.00      0.00         8\n",
      "          3       0.00      0.00      0.00         7\n",
      "          4       0.00      0.00      0.00         2\n",
      "          5       0.21      0.30      0.25       155\n",
      "          6       0.00      0.00      0.00         1\n",
      "          7       0.00      0.00      0.00         2\n",
      "          8       0.00      0.00      0.00         6\n",
      "          9       0.00      0.00      0.00         3\n",
      "         10       0.16      0.15      0.15       132\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00         2\n",
      "         13       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         2\n",
      "         15       0.19      0.16      0.17       116\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       0.00      0.00      0.00         2\n",
      "         19       0.00      0.00      0.00         2\n",
      "         20       0.12      0.08      0.10        71\n",
      "         21       0.00      0.00      0.00         2\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.00      0.00      0.00         0\n",
      "         25       0.17      0.09      0.12        53\n",
      "         27       0.00      0.00      0.00         1\n",
      "         30       0.17      0.07      0.10        27\n",
      "         35       0.00      0.00      0.00        14\n",
      "         37       0.00      0.00      0.00         2\n",
      "         40       0.00      0.00      0.00        16\n",
      "         45       0.00      0.00      0.00        10\n",
      "         50       0.00      0.00      0.00         5\n",
      "         55       0.00      0.00      0.00         3\n",
      "         60       0.00      0.00      0.00         2\n",
      "         65       0.00      0.00      0.00         4\n",
      "         90       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.25      0.26      0.25      1527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhheadquarters/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/dhheadquarters/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print(classification_report(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make this above into a 2x2 confusion matrix so it isnt so complicated.\n",
    "#random intensification of hurricanes is now a '1' and no random intensification is now a '0'\n",
    "#if dvmax_answers is greater or equal to 25 knots then we store a 1 in answer column else we store 0\n",
    "\n",
    "def convert_dvmax(dvmax_array):\n",
    "    '''converts a dvmax of 25 knots and above into a one\n",
    "    converts a dvmax of less then 25 knots into a zero'''\n",
    "    \n",
    "    rih_answer = []\n",
    "    for dvmax in dvmax_array:\n",
    "        if dvmax >= 25:\n",
    "            rih_answer.append(1)\n",
    "        else:\n",
    "            rih_answer.append(0)\n",
    "            \n",
    "    return rih_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_converted = convert_dvmax(y_test)\n",
    "rfc_predict_converted = convert_dvmax(rfc_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1363   26]\n",
      " [ 118   20]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.98      0.95      1389\n",
      "          1       0.43      0.14      0.22       138\n",
      "\n",
      "avg / total       0.88      0.91      0.88      1527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now lets do the above calculations for precision, recall, f1 score and have a better idea of whats happening\n",
    "\n",
    "print(confusion_matrix(y_test_converted, rfc_predict_converted))\n",
    "print(classification_report(y_test_converted, rfc_predict_converted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to find the FAR and TSS and POD scores\n",
    "#these can be better calculated with the help of the below formula to find true positives, false positive, true negative, false negative\n",
    "#https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal \n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.12620903371208564\n",
      "FAR(False Alarm Ratio) is: 0.5652173913043478\n",
      "POD(Probability of Detection) is: 0.14492753623188406\n"
     ]
    }
   ],
   "source": [
    "#now that we have a nice function to find the tp, fp, tn, fn \n",
    "#lets find the TSS, FAR, POD score\n",
    "\n",
    "tp, fp, tn, fn = perf_measure(y_test_converted, rfc_predict_converted)\n",
    "\n",
    "pss = ((tp*tn)-(fp*fn)) / ((tp + fn) * (fp + tn))\n",
    "far = (fp) / (tp+fp)\n",
    "pod = tp / (tp+fn)\n",
    "print(\"PSS(Pierces Skill Score) or TSS(True Skill Score) is: \" + str(pss))\n",
    "print(\"FAR(False Alarm Ratio) is: \" + str(far))\n",
    "print(\"POD(Probability of Detection) is: \" + str(pod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier() with no adjustments to the hyperparameters\n",
    "#### the below scores will adjust between each time we run the above program. \n",
    "- PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.12620903371208564\n",
    "- FAR(False Alarm Ratio) is: 0.5652173913043478\n",
    "- POD(Probability of Detection) is: 0.14492753623188406\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting Hyperparameters\n",
    "#### this has gotten easier with the implementation of RandomizedSearchCV() \n",
    "#### lets see which hyperparameters we should use. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhheadquarters/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] warm_start=True, n_estimators=1962, min_samples_split=80, min_samples_leaf=10, max_features=auto, max_depth=353, criterion=entropy \n",
      "[CV] warm_start=True, n_estimators=1962, min_samples_split=80, min_samples_leaf=10, max_features=auto, max_depth=353, criterion=entropy \n",
      "[CV] warm_start=True, n_estimators=1962, min_samples_split=80, min_samples_leaf=10, max_features=auto, max_depth=353, criterion=entropy \n",
      "[CV] warm_start=False, n_estimators=1962, min_samples_split=60, min_samples_leaf=5, max_features=auto, max_depth=59, criterion=entropy \n",
      "[CV] warm_start=False, n_estimators=1962, min_samples_split=60, min_samples_leaf=5, max_features=auto, max_depth=59, criterion=entropy \n",
      "[CV] warm_start=False, n_estimators=1962, min_samples_split=60, min_samples_leaf=5, max_features=auto, max_depth=59, criterion=entropy \n",
      "[CV] warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini \n",
      "[CV] warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini \n",
      "[CV]  warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini, total=   0.7s\n",
      "[CV] warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini \n",
      "[CV]  warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini, total=   0.7s\n",
      "[CV] warm_start=True, n_estimators=1424, min_samples_split=60, min_samples_leaf=2, max_features=auto, max_depth=206, criterion=gini \n",
      "[CV]  warm_start=True, n_estimators=80, min_samples_split=15, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=gini, total=   0.8s\n",
      "[CV] warm_start=True, n_estimators=1424, min_samples_split=60, min_samples_leaf=2, max_features=auto, max_depth=206, criterion=gini \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-baeeb5dfe7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mrfc_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#print_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TUNING HYPERPARAMETERS - THIS TAKES 12 MINUTES TO RUN - \n",
    "#https://medium.com/@hjhuney/implementing-a-random-forest-classification-model-in-python-583891c99652\n",
    "\n",
    "#number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 80, stop = 2500, num = 10)]\n",
    "\n",
    "#number of features at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "#max depth \n",
    "max_depth = [int(x) for x in np.linspace(10, 500, num = 11)]\n",
    "\n",
    "#min_samples split\n",
    "min_samples_split = [2, 5, 10, 15, 30, 60, 80, 100]\n",
    "\n",
    "#min samples leaf\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "\n",
    "#warm start\n",
    "warm_start = ['True', 'False']\n",
    "\n",
    "\n",
    "#create random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,#\n",
    "    'criterion': criterion,\n",
    "    'warm_start': warm_start\n",
    "    \n",
    "}\n",
    "\n",
    "#random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid,\n",
    "                               n_iter = 100, cv = 3, verbose = 2, random_state = 42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "#fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "\n",
    "#print_results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameters from the above program that takes 12 minutes to run\n",
    "\n",
    "After running the program we were able to find some hyperparameters to train on. It left us with a few that still needed to be adjusted. the n_estimators has done best at 2000 and sometimes the above had it with less then that. \n",
    "\n",
    "- n_estimators = The number of decision trees used within the forest\n",
    "- max_depth = the depth of eacg tree in the forest\n",
    "- max_features = size of random subsets of features when we split a node\n",
    "- min_samples_leaf = The number of samples required to be at a leaf node\n",
    "- warm_start = This allows the weights to start off from where the previous weights left off.  \n",
    "- criterion - 'gini - Gini impurity measures the degree or probability of a particular variable being wrongly classified when it is randomly chosen.\n",
    "\n",
    "\n",
    "                              \n",
    "https://stackoverflow.com/questions/46234806/what-n-estimators-and-max-features-means-in-randomforestregressor/46234913                            \n",
    "https://stackoverflow.com/questions/23939750/understanding-max-features-parameter-in-randomforestregressor\n",
    "https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d\n",
    "https://stackoverflow.com/questions/42757892/how-to-use-warm-start\n",
    "https://blog.quantinsti.com/gini-index/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=304, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start='True')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets run this program with the added hyperparameters and store the classifier as rfc_2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 66)\n",
    "\n",
    "rfc_2 = RandomForestClassifier(n_estimators = 2000,\n",
    "                               max_depth = 304,\n",
    "                               max_features = 'sqrt',\n",
    "                               min_samples_leaf = 1,\n",
    "                               min_samples_split = 2,\n",
    "                               warm_start = 'True',\n",
    "                               criterion = 'gini'\n",
    "                              )\n",
    "\n",
    "rfc_2.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing the confusion matrix below: \n",
      "\n",
      "[[1357   32]\n",
      " [  96   42]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95      1389\n",
      "          1       0.57      0.30      0.40       138\n",
      "\n",
      "avg / total       0.90      0.92      0.90      1527\n",
      "\n",
      "PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.28130966913951233\n",
      "FAR(False Alarm Ratio) is: 0.43243243243243246\n",
      "POD(Probability of Detection) is: 0.30434782608695654\n"
     ]
    }
   ],
   "source": [
    "#predit the X_test\n",
    "rfc_2_predict = rfc_2.predict(X_test)\n",
    "\n",
    "#convert to binary\n",
    "y_test_converted_2 = convert_dvmax(y_test)\n",
    "rfc_predict_converted_2 = convert_dvmax(rfc_2_predict)\n",
    "\n",
    "print('printing the confusion matrix below: \\n')\n",
    "print(confusion_matrix(y_test_converted_2, rfc_predict_converted_2))\n",
    "print(classification_report(y_test_converted_2, rfc_predict_converted_2))\n",
    "\n",
    "tp2, fp2, tn2, fn2 = perf_measure(y_test_converted_2, rfc_predict_converted_2)\n",
    "\n",
    "pss2 = ((tp2*tn2)-(fp2*fn2)) / ((tp2 + fn2) * (fp2 + tn2))\n",
    "far2 = (fp2) / (tp2+fp2)\n",
    "pod2 = tp2 / (tp2+fn2)\n",
    "print(\"PSS(Pierces Skill Score) or TSS(True Skill Score) is: \" + str(pss2))\n",
    "print(\"FAR(False Alarm Ratio) is: \" + str(far2))\n",
    "print(\"POD(Probability of Detection) is: \" + str(pod2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect. \n",
    "#### We were told that our target score would be having a TSS score of between 25% & 30%. \n",
    "#### We are consistently performing at around 28%. \n",
    "##### After tuning the hyperparameters... we can expect the scores to be similar to the below\n",
    "- PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.28130966913951233\n",
    "- FAR(False Alarm Ratio) is: 0.43243243243243246\n",
    "- POD(Probability of Detection) is: 0.30434782608695654"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets use feature extraction to see which features are carrying the most weight in determining the answer\n",
    "#https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/\n",
    "#https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store feature labels in a list\n",
    "feat_labels = X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featured_labels(classifier):\n",
    "    features = {}\n",
    "    for feature in zip(feat_labels, classifier.feature_importances_):\n",
    "        features.update([(feature[0], feature[1])])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = featured_labels(rfc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PX10', 0.018137557297787123),\n",
       " ('PX20', 0.01853816260425649),\n",
       " ('PX30', 0.01924445652198539),\n",
       " ('PC1', 0.01952097278062145),\n",
       " ('PER', 0.01995965871261012),\n",
       " ('RHLO', 0.020781323938904313),\n",
       " ('DTL', 0.020879745017545574),\n",
       " ('PX50', 0.021041666642867374),\n",
       " ('TBMX', 0.0219481456990902),\n",
       " ('BTAV', 0.02210909955508751),\n",
       " ('PC2', 0.02255573573706108),\n",
       " ('AVBT2', 0.022896805589355168),\n",
       " ('AVBT', 0.022898514004941712),\n",
       " ('SDBT2', 0.022939244635537613),\n",
       " ('RHMD', 0.0229908179652265),\n",
       " ('vmax', 0.023331201247694746),\n",
       " ('SDBT', 0.02339243482424704),\n",
       " ('T250', 0.02401440283301213),\n",
       " ('DIVC', 0.02437954321673808),\n",
       " ('D200', 0.024585403617526373),\n",
       " ('EPOS', 0.02507771419851471),\n",
       " ('T200', 0.02524123471879942),\n",
       " ('Z850', 0.02560720821777984),\n",
       " ('UMOV', 0.025745684105206057),\n",
       " ('PSLV', 0.026088136860923147),\n",
       " ('EPSS', 0.026205834949967626),\n",
       " ('TPWC', 0.026332716275272058),\n",
       " ('POT', 0.027064393074652554),\n",
       " ('MSLP', 0.02742933689250113),\n",
       " ('U200', 0.027823716643137472),\n",
       " ('SHTD', 0.028186882401020574),\n",
       " ('clat', 0.028867521880122794),\n",
       " ('SHRG', 0.02901595347272033),\n",
       " ('SHRD2', 0.029123905151503024),\n",
       " ('RSST', 0.029554157594761342),\n",
       " ('VS', 0.02989434750889842),\n",
       " ('SHGC', 0.03060609922225177),\n",
       " ('clon', 0.031050824108159302),\n",
       " ('SHRD', 0.031249533484226245),\n",
       " ('ENSS', 0.03368990679748615)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets sort in order of least to most important\n",
    "sorted_features = sorted(features.items(), key=lambda kv: kv[1])\n",
    "sorted_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Its interesting as the columns are all really close in importance\n",
    "## We want to get the TSS score above the 30% marker and lets try a few things to get there\n",
    "\n",
    "#### we have a problem where the top features are consistently changing. So where do we cut off the amount of features to train on? Should we do 20 columns or 30 columns. The elbow method doesnt really appear to really work with this problem. \n",
    "LETS FIND THE TOP PERFORMING COLUMNS IN A DIFFERENT WAY\n",
    "\n",
    "In sports there is often a players ranking system that is voted on by the players. This ranking system tends to carry the most weight within the sports world as the players are being ranked by other players. The players are being ranked by the people that play against or with them.\n",
    "\n",
    "We need the best features. We need the first place features. We need to see what features can get to first place.  We need the players that are able to get to the top of the program as the most important player. \n",
    "\n",
    "LETS CREATE A FUNCTION TO FIND THE BEST PLAYER ON THE TEAM WITHIN THE GIVEN ITERATION OF THE PROGRAM \n",
    "- Find the top performing FEATURE/COLUMN/PLAYER in dataframe.\n",
    "- Take the top performing FEATURE/COLUMN/PLAYER in the dataframe out. Store it in a list as first place. :)\n",
    "- Run the program again without the first place performer and we will be forced into having a new top performer. store this new top performer in the same list as above. When appended it will become second place. \n",
    "- Keep taking away the programs most important feature which will force it to find a new feature to rely on. We can get an understanding of the order of things with this. we will end up with a top 40 features in order of importance.\n",
    "\n",
    "I understand that the program will be computationally intensive. I also really want to get to 31% :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will need to take warm_start off during the loop searching for best rows. \n",
    "#warm start is really interesting to me and something that will be tinkered with quite a bit in the future.\n",
    "#it has been very inconsistent but the concept of building on the previous weights is interesting.\n",
    "#Lets proceed :)\n",
    "\n",
    "def top_performer(train_df, y):\n",
    "    '''find top performer and drop from df'''\n",
    "    \n",
    "    #have to have something already in the best_rows list as it doesnt run without it so we put back in 'date'\n",
    "    best_features = ['date']\n",
    "    \n",
    "    #i need to store the original df as its own entity in order to start from scratch below\n",
    "    df = train_df.copy()\n",
    "    \n",
    "    worst_features = []\n",
    "    #loop through for the duration of the columns which is 40 loops\n",
    "    for number in range(train_df.shape[1]):\n",
    "         \n",
    "        train_df = df.copy()    \n",
    "        #drop the best rows here\n",
    "        print('\\n')\n",
    "        print('The best FEATURES are: ')\n",
    "        print(best_features)\n",
    "        train_df = train_df.drop(best_features, axis = 1)\n",
    "        \n",
    "        if train_df.shape[1] >= 5:\n",
    "\n",
    "            print('the new train_df shape is')\n",
    "            print(train_df.shape)\n",
    "            \n",
    "            \n",
    "            #need to do train_test_split too\n",
    "            X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(train_df, y, test_size = .33, random_state = 66)\n",
    "            \n",
    "            #we need to take warm_start out for this. will keep everything else the same as for future\n",
    "            rfc_top = RandomForestClassifier(n_estimators = 2000,\n",
    "                                       max_depth = 304,\n",
    "                                       max_features = 'sqrt',\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       min_samples_split = 2,\n",
    "                                       criterion = 'gini'\n",
    "                                      )\n",
    "        \n",
    "            #fit to the \n",
    "            rfc_top.fit(X_train_top, y_train_top)\n",
    "            \n",
    "            #predict the answer\n",
    "            rfc_top_predict = rfc_top.predict(X_test_top)\n",
    "            \n",
    "            #convert into 0's and 1's\n",
    "            y_test_converted_top = convert_dvmax(y_test_top)\n",
    "            rfc_predict_converted_top = convert_dvmax(rfc_top_predict)\n",
    "            \n",
    "            #find top performing columns\n",
    "            sel = SelectFromModel(rfc_top)\n",
    "            sel.fit(X_train_top, y_train_top)\n",
    "            \n",
    "            #store feature labels to columns\n",
    "            feat_labels = train_df.columns.values\n",
    "            \n",
    "            #see the list of featured labels\n",
    "            features = featured_labels(rfc_top)\n",
    "            \n",
    "            #sort the features\n",
    "            sorted_features = sorted(features.items(), key = lambda kv: kv[1])\n",
    "            best_feature = sorted_features[-1][0]\n",
    "            print('the best feature and its value is: ')\n",
    "            print(sorted_features[-1])\n",
    "            \n",
    "            print('the best features is ' + str(best_feature))\n",
    "            print('the features list is: \\n')\n",
    "            print(sorted_features)\n",
    "            \n",
    "            \n",
    "            #append the best_rows\n",
    "            best_features.append(best_feature)\n",
    "            #best_rows = best_rows.append(best_feature)\n",
    "            \n",
    "            worst_features.append(train_df.columns.values)\n",
    "            \n",
    "            \n",
    "        \n",
    "        else:\n",
    "            worst_features.append(train_df.columns.values)\n",
    "            break\n",
    "    return best_features, worst_features\n",
    "            \n",
    "        \n",
    "     \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The best FEATURES are: \n",
      "['date']\n",
      "the new train_df shape is\n",
      "(4626, 40)\n",
      "the best feature and its value is: \n",
      "('ENSS', 0.03272077537717958)\n",
      "the best features is ENSS\n",
      "the features list is: \n",
      "\n",
      "[('PC1', 0.017806089442074454), ('PX10', 0.018253707821621824), ('PX20', 0.018775811803242528), ('PX30', 0.0194007830818163), ('PER', 0.019909617455188225), ('RHLO', 0.02065326031451124), ('DTL', 0.020981262331313706), ('PX50', 0.02108194656491696), ('TBMX', 0.021787737481052765), ('BTAV', 0.022185413306782385), ('PC2', 0.02220599570341558), ('RHMD', 0.02261282557794097), ('AVBT', 0.022644888371110033), ('AVBT2', 0.022648053353894065), ('SDBT2', 0.02284707066363435), ('vmax', 0.023035344447630945), ('SDBT', 0.023264186936105304), ('T250', 0.023943898399498516), ('DIVC', 0.0244332811757897), ('D200', 0.02476535460541729), ('EPOS', 0.024955343806511862), ('Z850', 0.02535665540270859), ('T200', 0.025629988490588226), ('PSLV', 0.025908322927838873), ('EPSS', 0.025928128824553084), ('UMOV', 0.0265537549905905), ('TPWC', 0.026697652199457373), ('POT', 0.026877592278065868), ('MSLP', 0.027700819921277837), ('SHTD', 0.028191904640627576), ('U200', 0.02828396266791636), ('clat', 0.028830574391788526), ('SHRD2', 0.02972672160515754), ('VS', 0.029753128253597706), ('SHRG', 0.029837992541545073), ('RSST', 0.029932735722731432), ('SHGC', 0.03090165644496702), ('clon', 0.03128025219777629), ('SHRD', 0.03169550847816349), ('ENSS', 0.03272077537717958)]\n",
      "\n",
      "\n",
      "The best FEATURES are: \n",
      "['date', 'ENSS']\n",
      "the new train_df shape is\n",
      "(4626, 39)\n",
      "the best feature and its value is: \n",
      "('SHRD', 0.03341188775535004)\n",
      "the best features is SHRD\n",
      "the features list is: \n",
      "\n",
      "[('TPWC', 0.018593702965985115), ('SDBT2', 0.018757318511668078), ('PX10', 0.01944389347182263), ('PX30', 0.019703816259057903), ('PER', 0.020281790912096014), ('RHLO', 0.02060525365062632), ('RHMD', 0.021499762885172618), ('PX20', 0.02191503210951668), ('PX50', 0.022072165113575692), ('RSST', 0.022705851294945397), ('PC2', 0.023148036661495296), ('EPOS', 0.02325091043641938), ('AVBT', 0.02331954733996196), ('PC1', 0.023696375612041718), ('AVBT2', 0.023850822516765388), ('SDBT', 0.02385815832763577), ('vmax', 0.024471090154142495), ('T200', 0.024667130176783382), ('DIVC', 0.02497609443118158), ('D200', 0.02498949099288954), ('T250', 0.026135394589273525), ('Z850', 0.026183928049579603), ('EPSS', 0.02633103310736613), ('PSLV', 0.026623810982597595), ('DTL', 0.026698808242362516), ('ENSS', 0.02682291224641648), ('SHGC', 0.02729498268760273), ('clat', 0.028057834609313225), ('POT', 0.02832782540745177), ('U200', 0.02908630660998582), ('MSLP', 0.02918780919161804), ('BTAV', 0.029223054933584337), ('UMOV', 0.030821326260695295), ('SHRG', 0.03137013366770345), ('TBMX', 0.031474351164813515), ('SHRD2', 0.03164640070691183), ('clon', 0.0326466048021285), ('SHTD', 0.03284935116146262), ('SHRD', 0.03341188775535004)]\n",
      "\n",
      "\n",
      "The best FEATURES are: \n",
      "['date', 'ENSS', 'SHRD']\n",
      "the new train_df shape is\n",
      "(4626, 38)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-f77e02058b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvmax_answers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworst_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_performer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-132-8f277d5ab729>\u001b[0m in \u001b[0;36mtop_performer\u001b[0;34m(train_df, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#fit to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mrfc_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_top\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_top\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#predict the answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#THIS FUNCTION TAKES TIME TO RUN :) MAYBE AN HOUR AND A HALF.\n",
    "\n",
    "#train_test = train_test.drop('date', 1)\n",
    "X = df_clean.copy()\n",
    "#X = X.drop('date', 1)\n",
    "y = dvmax_answers.astype(int)\n",
    "\n",
    "best_features, worst_features = top_performer(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#THIS IS A LIST OF THE ABOVE TOP FEATURES AFTER THE TOP_PERFORMER FUNCTION\n",
    "#We will be storing the columns in order of there feature \n",
    "#importance based off of the above function top_performer. \n",
    "\n",
    "feature_order = ['ENSS', 'SHGC', 'SHRD', 'clon', 'SHRG', 'SHRD2', 'U200', 'VS', 'MSLP', 'RSST', 'POT', 'TPWC',\n",
    "             'vmax', 'SHTD', 'clat', 'UMOV', 'PSLV', 'T200', 'T250', 'EPOS', 'EPSS', 'Z850', 'DIVC', 'D200', \n",
    "             'RHMD', 'RHLO', 'PER', 'DTL', 'PC2', 'AVBT2', 'AVBT', 'BTAV', 'TBMX', 'SDBT2', 'SDBT', 'PX50', \n",
    "             'PX30', 'PX10', 'PX20', 'PC1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHAT NUMBER OF TOP FEATURES SHOULD WE USE?\n",
    "#find out what number of features is the best for getting the highest accuracy\n",
    "#were not going to use warm_start right now and then bring it in after we find out our best feature amount.\n",
    "\n",
    "\n",
    "def feature_number(dataframe, features_list, y):\n",
    "    '''what is the correct amount of features?'''\n",
    "    \n",
    "    pss_scores = [0, 0]\n",
    "    far_scores = [0, 0]\n",
    "    pod_scores = [0, 0]\n",
    "    \n",
    "    for number in range(len(features_list)):\n",
    "        \n",
    "        if number >= 2:\n",
    "            \n",
    "            #create the training_matrix\n",
    "            train_columns = features_list[:number]\n",
    "            \n",
    "            print('We are now training on the top ' + str(number) + ' columns: \\n\\n')\n",
    "            \n",
    "            print('The columns are: ' + str(train_columns))\n",
    "            \n",
    "            #adjust the dataframe to contain the correct columns\n",
    "            df = dataframe[train_columns]            \n",
    "        \n",
    "            #train_test_split the data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(df, y, test_size = .33, random_state = 66)\n",
    "        \n",
    "            #Put in the classifier and take out the warm_start\n",
    "            rfc = RandomForestClassifier(n_estimators = 2000,\n",
    "                                max_depth = 304,\n",
    "                                max_features = 'sqrt',\n",
    "                                min_samples_leaf = 1,\n",
    "                                min_samples_split = 2,\n",
    "                                criterion = 'gini'\n",
    "                                )\n",
    "        \n",
    "            #train this classifier\n",
    "            rfc.fit(X_train, y_train)\n",
    "        \n",
    "            #predict the answers\n",
    "            rfc_predict = rfc.predict(X_test)\n",
    "            \n",
    "            #convert the answers into 1's & 0's\n",
    "            y_test_converted = convert_dvmax(y_test)\n",
    "            rfc_predict_converted = convert_dvmax(rfc_predict)\n",
    "            \n",
    "            print(confusion_matrix(y_test_converted, rfc_predict_converted))\n",
    "            print(classification_report(y_test_converted, rfc_predict_converted))\n",
    "            \n",
    "            tp, fp, tn, fn = perf_measure(y_test_converted, rfc_predict_converted)\n",
    "\n",
    "            pss = ((tp*tn)-(fp*fn)) / ((tp + fn) * (fp + tn))\n",
    "            far = (fp) / (tp+fp)\n",
    "            pod = tp / (tp+fn)\n",
    "            print('Training with the top ' + str(number) + ' of features we achieve: ')\n",
    "            print(\"PSS(Pierces Skill Score) or TSS(True Skill Score) is: \" + str(pss))\n",
    "            print(\"FAR(False Alarm Ratio) is: \" + str(far))\n",
    "            print(\"POD(Probability of Detection) is: \" + str(pod))\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            pss_scores.append(pss)\n",
    "            far_scores.append(far)\n",
    "            pod_scores.append(pod)\n",
    "            \n",
    "                  \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are now training on the top 2 columns: \n",
      "\n",
      "\n",
      "The columns are: ['ENSS', 'SHGC']\n",
      "[[1278  111]\n",
      " [ 118   20]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.92      0.92      1389\n",
      "          1       0.15      0.14      0.15       138\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1527\n",
      "\n",
      "Training with the top 2 of features we achieve: \n",
      "PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.06501392932043698\n",
      "FAR(False Alarm Ratio) is: 0.8473282442748091\n",
      "POD(Probability of Detection) is: 0.14492753623188406\n",
      "\n",
      "\n",
      "\n",
      "We are now training on the top 3 columns: \n",
      "\n",
      "\n",
      "The columns are: ['ENSS', 'SHGC', 'SHRD']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-23d9dd0bf34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#THIS FUNCTION TAKES A LONG TIME TO RUN:) Maybe an hour or so.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-140-76b29cc036c9>\u001b[0m in \u001b[0;36mfeature_number\u001b[0;34m(dataframe, features_list, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m#predict the answers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mrfc_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#convert the answers into 1's & 0's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    587\u001b[0m         Parallel(n_jobs=n_jobs, verbose=self.verbose, backend=\"threading\")(\n\u001b[1;32m    588\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccumulate_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproba\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_proba\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36maccumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccumulate_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#THIS FUNCTION TAKES A LONG TIME TO RUN:) Maybe an hour or so. \n",
    "feature_number(X, feature_order, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are training with the top 27 features:\n",
      "Those columns are Index(['ENSS', 'SHGC', 'SHRD', 'clon', 'SHRG', 'SHRD2', 'U200', 'VS', 'MSLP',\n",
      "       'RSST', 'POT', 'TPWC', 'vmax', 'SHTD', 'clat', 'UMOV', 'PSLV', 'T200',\n",
      "       'T250', 'EPOS', 'EPSS', 'Z850', 'DIVC', 'D200', 'RHMD', 'RHLO', 'PER'],\n",
      "      dtype='object')\n",
      "[[1361   28]\n",
      " [  81   57]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96      1389\n",
      "          1       0.67      0.41      0.51       138\n",
      "\n",
      "avg / total       0.92      0.93      0.92      1527\n",
      "\n",
      "Training with the top warm_start having the same records achieves a success of: \n",
      "PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.39288509093185586\n",
      "FAR(False Alarm Ratio) is: 0.32941176470588235\n",
      "POD(Probability of Detection) is: 0.41304347826086957\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LETS DUPLICATE WHAT WE JUST ACHIEVED WITH THE TOP 27 ROWS:) \n",
    "#THE HIGHEST SCORE WAS ACHIEVED WITH 27 FEATURES\n",
    "#the above was training with 27 features. with the inclusion of the number 0. that means we will be including\n",
    "#the top 28 columns in the final dataframe\n",
    "df = df_clean[feature_order[:27]]\n",
    "y = dvmax_answers.astype(int)\n",
    "\n",
    "print('We are training with the top ' + str(len(df.columns)) + ' features:')\n",
    "print('Those columns are ' + str(df.columns))\n",
    "\n",
    "\n",
    "    \n",
    "#train_test_split the data\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(df, y, test_size = .33, random_state = 66)\n",
    "        \n",
    "#Put in the classifier and take out the warm_start\n",
    "rfc_final = RandomForestClassifier(n_estimators = 2000,\n",
    "                     max_depth = 304,\n",
    "                     max_features = 'sqrt',\n",
    "                     min_samples_leaf = 1,\n",
    "                     min_samples_split = 2,\n",
    "                     criterion = 'gini',\n",
    "                     warm_start = 'True'\n",
    "                     )\n",
    "        \n",
    "#train this classifier\n",
    "rfc_final.fit(X_train_final, y_train_final)\n",
    "#lets keep the current weights and continue training for another 2000 n_estimators.\n",
    "#the warm_start hyperparameter has been something that could be essential in exponential growth.\n",
    "#It has been inconsistent with the predictions. however. it has added more then it has hurt.\n",
    "#for that reason I will be keeping warm_start in and adding another 2000 forests.\n",
    "rfc_final.set_params(n_estimators = 4000)\n",
    "rfc_final.fit(X_train_final, y_train_final)\n",
    "\n",
    "#predict the answers\n",
    "rfc_predict_final = rfc_final.predict(X_test_final)\n",
    "\n",
    "#convert the answers into 1's & 0's\n",
    "y_test_converted_final = convert_dvmax(y_test_final)\n",
    "rfc_predict_converted_final = convert_dvmax(rfc_predict_final)\n",
    "            \n",
    "print(confusion_matrix(y_test_converted_final, rfc_predict_converted_final))\n",
    "print(classification_report(y_test_converted_final, rfc_predict_converted_final))\n",
    "            \n",
    "tp2, fp2, tn2, fn2 = perf_measure(y_test_converted_final, rfc_predict_converted_final)\n",
    "\n",
    "pss2 = ((tp2*tn2)-(fp2*fn2)) / ((tp2 + fn2) * (fp2 + tn2))\n",
    "far2 = (fp2) / (tp2+fp2)\n",
    "pod2 = tp2 / (tp2+fn2)\n",
    "print('AFTER TRAINING ON THE TOP 27 COLUMNS WE ACHIEVE SCORES OF: ')\n",
    "print(\"PSS(Pierces Skill Score) or TSS(True Skill Score) is: \" + str(pss2))\n",
    "print(\"FAR(False Alarm Ratio) is: \" + str(far2))\n",
    "print(\"POD(Probability of Detection) is: \" + str(pod2))\n",
    "print('\\n\\n')\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT :)\n",
    "This program has the PSS score at numbers that range between 36 and 39.9%\n",
    "Adjusting the number of features between 27 and 28 features has shown mixed results. :)\n",
    "\n",
    "WE CAN EXPECT our highest SCORES IN THE RANGE OF:\n",
    "- PSS(Pierces Skill Score) or TSS(True Skill Score) is: 0.39869158293423484\n",
    "- FAR(False Alarm Ratio) is: 0.3409090909090909\n",
    "- POD(Probability of Detection) is: 0.42028985507246375\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As much as I would love to continue tinkering with this program in order to achieve above 50%... It is time to finish up school and go back to work. :)\n",
    "\n",
    "The issue of random intensification is going to be better understood in the near future. There are too many smart people at NASA and NOAA working on this right now for there not to be an exponential breakthrough in the way we predict when this will happen. \n",
    "\n",
    "One solution is to bring in the correct data point that will allow the program to achieve a higher success rate. \n",
    "What is that feature though? I am optimistic it will be found soon. \n",
    "\n",
    "However:\n",
    "\n",
    "Another solution is to assume its possible within the above dataframe. If this is the case then we will need to come up with more advanced ways of training the algorithm to find patterns. \n",
    "\n",
    "The warm_start method is interesting to me and one I tinkered a lot with. The idea that we could take a trained classifier and then add in more records to that already trained classifier and grow from those previously received weights is potentially really important. The warm_start results were frustratingly mixed. It is interesting in concept and with something this complex it could be helpful to start the program with a head start. Or some version of a head start. I 'm not sold on the fact that warm_start is the answer. I am becoming more intrigued by the concept it brings to the table. A custom warm_start formula could yield higher results. The warm_start method within random forest is ulitimately pretty limiting. \n",
    "\n",
    "I kicked around a ton of ideas throughout the creation of this project and feel like 51% is more then possible with the above data. We might need to aggregate the columns with PCA and then bring in adaboost. We might be able to stack 2 decision tree classifiers together and adjust the weights manually between the stack. We might be able to bring in a custom warm_start method to bring previously learned information to the forefront. Whatever ends up being the correct answer is going to help in other dataframes that are incredibly complex but still have several readily available features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THERE IS ANOTHER DATASET THAT CAN BE USED TO TEST THE ABOVE CLASSIFIER. \n",
    "#THE NEW DATASET HAS THE PREDICT COLUMN DELETED FROM THE DF.\n",
    "#I WANTED TO SUBMIT THIS NOW AS TO MAKE SURE EVERYTHING LOOKED GOOD\n",
    "#BEFORE I SENT MY PREDICTIONS ON THE NEW DATASET OVER\n",
    "#TO THE POTENTIAL EMPLOYERS. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
